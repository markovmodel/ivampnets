{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ac4f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils import data\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad358a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = 1\n",
    "number_subsystems = 10\n",
    "fake_dims = 10\n",
    "output_sizes = [2 for _ in range(number_subsystems)]\n",
    "# tau list for timescales estimation\n",
    "msmlags = np.arange(1, 10)\n",
    "\n",
    "# Batch size for Stochastic Gradient descent\n",
    "batch_size = 10000\n",
    "\n",
    "# How many hidden layers the network chi has\n",
    "network_depth = 3\n",
    "\n",
    "# Width of every layer of chi\n",
    "layer_width = 30\n",
    "\n",
    "# Learning rate used for the ADAM optimizer\n",
    "\n",
    "# create a list with the number of nodes for each layer\n",
    "nodes = [layer_width]*network_depth\n",
    "\n",
    "# Definition of the hidden Markov transition matrices\n",
    "eps_list = np.linspace(0.,.1, number_subsystems+1)[1:]\n",
    "lam = 0 #0.04\n",
    "# Number of unformative noise dimensions\n",
    "dim_noise = 10\n",
    "\n",
    "# How strong the fake subsystem is\n",
    "factor_fake = 3.\n",
    "# How large the noise in the mask for regularization is\n",
    "noise = 2.\n",
    "# Threshold after which the attention weight is set to zero\n",
    "cutoff=0.9\n",
    "\n",
    "# Learning rate\n",
    "learning_rate=0.005\n",
    "# epsilon for inversion of symmetric matrices\n",
    "epsilon=1e-8\n",
    "# score method\n",
    "score_mode='regularize' # one of ('trunc', 'regularize', 'clamp', 'old')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c9347",
   "metadata": {},
   "source": [
    "### Create toymodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6226e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples import HyperCube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a326b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "toymodel = HyperCube(eps_list, lam=lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d52c5f8",
   "metadata": {},
   "source": [
    "### Sample hidden and observable trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6544310",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = np.pi / 4 * np.ones(number_subsystems//2)\n",
    "hidden_state_traj, observable_traj = toymodel.generate_traj(100000, angles=angles, dim_noise=dim_noise)\n",
    "hidden_state_traj_valid, observable_traj_valid = toymodel.generate_traj(10000, angles=angles, dim_noise=dim_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caba8e29",
   "metadata": {},
   "source": [
    "### Define training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d68e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeptime.util.data import TrajectoryDataset\n",
    "\n",
    "train_data = TrajectoryDataset(lagtime=tau, trajectory=observable_traj.astype('float32'))\n",
    "val_data = TrajectoryDataset(lagtime=tau, trajectory=observable_traj_valid.astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8985ac87",
   "metadata": {},
   "source": [
    "### Define networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb4a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masks import Mask\n",
    "from collections import OrderedDict\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)\n",
    "input_size = observable_traj.shape[1] \n",
    "mask = Mask(input_size, number_subsystems, mean=torch.Tensor(train_data.data.mean(0)),\n",
    "            std=torch.Tensor(train_data.data.std(0)), factor_fake=factor_fake, noise=noise, \n",
    "            device=device, cutoff=cutoff)\n",
    "mask.to(device=device)\n",
    "lobes = []\n",
    "for output_size in output_sizes:\n",
    "    lobe_dict = OrderedDict([('Layer_input', nn.Linear(input_size, layer_width)),\n",
    "                            ('Elu_input', nn.ELU())])\n",
    "    for d in range(network_depth):\n",
    "        lobe_dict['Layer'+str(d)]=nn.Linear(layer_width, layer_width)\n",
    "        lobe_dict['Elu'+str(d)]=nn.ELU()\n",
    "    lobe_dict['Layer_output']=nn.Linear(layer_width, output_size)\n",
    "    lobe_dict['Softmax']=nn.Softmax(dim=1) # obtain fuzzy probability distribution over output states\n",
    "    \n",
    "    lobe = nn.Sequential(\n",
    "        lobe_dict \n",
    "    )\n",
    "    lobes.append(lobe.to(device=device))\n",
    "\n",
    "print(mask)\n",
    "print(lobes)\n",
    "                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8772de4d",
   "metadata": {},
   "source": [
    "### Create iVAMPnets estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efacd90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ivampnets import iVAMPnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83916f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ivampnet = iVAMPnet(lobes, mask, device, learning_rate=learning_rate, epsilon=epsilon, score_mode=score_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca38304",
   "metadata": {},
   "source": [
    "### Plot mask before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c7aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples import plot_mask\n",
    "plot_mask(mask, skip=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78895a4",
   "metadata": {},
   "source": [
    "### Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader_train = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "loader_val = DataLoader(val_data, batch_size=len(val_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7361b8",
   "metadata": {},
   "source": [
    "### Create a tensorboard writer to observe performance during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1857cb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_installed = True\n",
    "if tensorboard_installed:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter('./runs/Cube10/')\n",
    "    input_model, _ = next(iter(loader_train))\n",
    "    # writer.add_graph(lobe, input_to_model=input_model.to(device))\n",
    "else:\n",
    "    writer=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e92b2ff",
   "metadata": {},
   "source": [
    "### Fit the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002b703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ivampnet.fit(loader_train, n_epochs=25, validation_loader=loader_val, mask=True, lam_decomp=2, \n",
    "                     lam_trace=0.5, start_mask=0, end_trace=1, tb_writer=writer, clip=False).fetch_model()\n",
    "mask.noise = 5\n",
    "model = ivampnet.fit(loader_train, n_epochs=25, validation_loader=loader_val, mask=True, lam_decomp=2, \n",
    "                     lam_trace=0, start_mask=0, end_trace=0, tb_writer=writer, clip=False).fetch_model()\n",
    "mask.noise = 10\n",
    "model = ivampnet.fit(loader_train, n_epochs=25, validation_loader=loader_val, mask=True, lam_decomp=2, \n",
    "                     lam_trace=0, start_mask=0, end_trace=0, tb_writer=writer, clip=False).fetch_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3984d128",
   "metadata": {},
   "source": [
    "### Plot the training and validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d7f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(*ivampnet.train_scores.T, label='training')\n",
    "plt.loglog(*ivampnet.validation_scores.T, label='validation')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('score')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144270b5",
   "metadata": {},
   "source": [
    "### Plot the mask after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d5348",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(mask, vmax=0.5, skip=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143348c9",
   "metadata": {},
   "source": [
    "### Estimate implied timescales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6d36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.noise=0 # set the noise to zero. \n",
    "its = []\n",
    "for tau_i in msmlags:\n",
    "    val_data_temp = TrajectoryDataset(lagtime=tau_i, trajectory=observable_traj_valid.astype('float32'))\n",
    "    its.append(model.timescales(val_data_temp.data, val_data_temp.data_lagged, tau_i))\n",
    "# Convert to array\n",
    "its = np.array(its)\n",
    "# Change the shape\n",
    "its = np.transpose(its, axes=[1,0,2])\n",
    "# Estimate the true timescales of the hidden Markov Chain\n",
    "eigvals_true = np.array(toymodel.eigvals_list_coupled).flatten()\n",
    "its_true = -1/np.log(eigvals_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1749ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples import plot_hypercube_its"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39413b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hypercube_its(its, msmlags, its_true, ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90807a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
